import argparse
import json
import os
from datetime import datetime

import matplotlib.pyplot as plt
import numpy as np


def plot_timings_from_json(json_file, save_plots=False, output_dir="timing_plots"):
    """
    Read timing data from JSON file and generate comprehensive plots.

    Parameters:
    json_file (str): Path to the JSON file generated by save_timings()
    save_plots (bool): Whether to save plots to files
    output_dir (str): Directory to save plots if save_plots is True
    """

    # Read the JSON file
    try:
        with open(json_file, "r") as f:
            data = json.load(f)
        print(f"Successfully loaded timing data from: {json_file}")
    except FileNotFoundError:
        print(f"Error: File '{json_file}' not found.")
        return
    except json.JSONDecodeError:
        print(f"Error: File '{json_file}' is not valid JSON.")
        return
    except Exception as e:
        print(f"Error reading file: {e}")
        return

    # Extract data
    timings = data.get("timings", {})
    statistics = data.get("statistics", {})
    metadata = data.get("metadata", {})

    if not timings:
        print("No timing data found in the JSON file.")
        return

    # Print summary
    print("\n" + "=" * 60)
    print("TIMING ANALYSIS REPORT")
    print("=" * 60)
    print(f"File: {json_file}")
    if metadata:
        print(f"Export timestamp: {metadata.get('export_timestamp', 'N/A')}")
        print(f"Total measurements: {metadata.get('total_measurements', 'N/A')}")
        print(f"Unique contexts: {metadata.get('unique_contexts', 'N/A')}")
    print(f"Operations found: {list(timings.keys())}")

    # Print statistics
    print("\n" + "-" * 40)
    print("OPERATION STATISTICS")
    print("-" * 40)
    for operation, times in timings.items():
        stats = statistics.get(operation, {})
        print(f"\n--- {operation} ---")
        print(f"  Count: {len(times)}")
        print(f"  Mean: {np.mean(times):.6f}s")
        print(f"  Std:  {np.std(times):.6f}s")
        print(f"  Min:  {np.min(times):.6f}s")
        print(f"  Max:  {np.max(times):.6f}s")
        print(f"  Total: {np.sum(times):.6f}s")

    # Create plots
    if save_plots:
        os.makedirs(output_dir, exist_ok=True)
        base_name = os.path.splitext(os.path.basename(json_file))[0]

    # Create a comprehensive figure with multiple subplots
    fig = plt.figure(figsize=(20, 15))

    # 1. Time series plot
    ax1 = plt.subplot(3, 3, 1)
    for operation, times in timings.items():
        ax1.plot(times, "o-", markersize=3, alpha=0.7, label=operation)
    ax1.set_title("Operation Times Over Sequence")
    ax1.set_ylabel("Time (seconds)")
    ax1.set_xlabel("Operation Instance")
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_yscale("log")  # Log scale for better visualization

    # 2. Box plot
    ax2 = plt.subplot(3, 3, 2)
    operation_names = list(timings.keys())
    operation_times = [timings[op] for op in operation_names]
    box_plot = ax2.boxplot(operation_times, labels=operation_names, showfliers=False)
    ax2.set_title("Distribution of Operation Times\n(without outliers)")
    ax2.set_ylabel("Time (seconds)")
    ax2.tick_params(axis="x", rotation=45)
    ax2.grid(True, alpha=0.3)
    ax2.set_yscale("log")

    # 3. Histograms
    ax3 = plt.subplot(3, 3, 3)
    for operation, times in timings.items():
        ax3.hist(times, bins=30, alpha=0.6, label=operation, density=True)
    ax3.set_title("Distribution of Operation Times")
    ax3.set_xlabel("Time (seconds)")
    ax3.set_ylabel("Density")
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_xscale("log")

    # 4. Cumulative time plot
    ax4 = plt.subplot(3, 3, 4)
    for operation, times in timings.items():
        cumulative_time = np.cumsum(times)
        ax4.plot(cumulative_time, label=operation)
    ax4.set_title("Cumulative Time per Operation")
    ax4.set_ylabel("Cumulative Time (seconds)")
    ax4.set_xlabel("Operation Instance")
    ax4.legend()
    ax4.grid(True, alpha=0.3)

    # 5. Percentage of total time
    ax5 = plt.subplot(3, 3, 5)
    total_times = {op: np.sum(times) for op, times in timings.items()}
    total_overall = sum(total_times.values())
    percentages = {op: (time / total_overall * 100) for op, time in total_times.items()}

    colors = plt.cm.Set3(np.linspace(0, 1, len(percentages)))
    wedges, texts, autotexts = ax5.pie(
        percentages.values(),
        labels=percentages.keys(),
        autopct="%1.1f%%",
        colors=colors,
        startangle=90,
    )
    ax5.set_title("Time Distribution by Operation")

    # 6. Operation frequency
    ax6 = plt.subplot(3, 3, 6)
    counts = [len(times) for times in timings.values()]
    bars = ax6.bar(
        operation_names,
        counts,
        color=plt.cm.Set3(np.linspace(0, 1, len(operation_names))),
    )
    ax6.set_title("Operation Frequency")
    ax6.set_ylabel("Number of Calls")
    ax6.tick_params(axis="x", rotation=45)

    # Add value labels on bars
    for bar, count in zip(bars, counts):
        ax6.text(
            bar.get_x() + bar.get_width() / 2,
            bar.get_height() + 0.1,
            f"{count}",
            ha="center",
            va="bottom",
        )

    # 7. Statistical summary table
    ax7 = plt.subplot(3, 3, 7)
    ax7.axis("tight")
    ax7.axis("off")

    # Prepare table data
    table_data = []
    headers = ["Operation", "Count", "Mean(s)", "Std(s)", "Total(s)"]
    for operation, times in timings.items():
        table_data.append(
            [
                operation,
                len(times),
                f"{np.mean(times):.6f}",
                f"{np.std(times):.6f}",
                f"{np.sum(times):.6f}",
            ]
        )

    table = ax7.table(
        cellText=table_data, colLabels=headers, loc="center", cellLoc="center"
    )
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1, 1.5)
    ax7.set_title("Statistical Summary")

    # 8. Throughput analysis (operations per second)
    ax8 = plt.subplot(3, 3, 8)
    throughput = {op: 1 / np.mean(times) for op, times in timings.items()}
    bars = ax8.bar(
        throughput.keys(),
        throughput.values(),
        color=plt.cm.Set3(np.linspace(0, 1, len(throughput))),
    )
    ax8.set_title("Throughput (Operations per Second)")
    ax8.set_ylabel("Ops/sec")
    ax8.tick_params(axis="x", rotation=45)

    # 9. Time ratio compared to fastest operation
    ax9 = plt.subplot(3, 3, 9)
    fastest_time = min(np.mean(times) for times in timings.values())
    time_ratios = {op: np.mean(times) / fastest_time for op, times in timings.items()}
    bars = ax9.bar(
        time_ratios.keys(),
        time_ratios.values(),
        color=plt.cm.Set3(np.linspace(0, 1, len(time_ratios))),
    )
    ax9.set_title("Time Ratio (Relative to Fastest Operation)")
    ax9.set_ylabel("Ratio")
    ax9.tick_params(axis="x", rotation=45)

    plt.tight_layout()

    if save_plots:
        plot_filename = os.path.join(output_dir, f"{base_name}_analysis.png")
        plt.savefig(plot_filename, dpi=300, bbox_inches="tight")
        print(f"Plots saved to: {plot_filename}")

    # plt.show()

    # Print performance insights
    print("\n" + "-" * 40)
    print("PERFORMANCE INSIGHTS")
    print("-" * 40)

    total_time = sum(np.sum(times) for times in timings.values())
    print(f"Total recorded time: {total_time:.3f} seconds")

    fastest_op = min(timings.items(), key=lambda x: np.mean(x[1]))
    slowest_op = max(timings.items(), key=lambda x: np.mean(x[1]))

    print(f"Fastest operation: {fastest_op[0]} ({np.mean(fastest_op[1]):.6f}s avg)")
    print(f"Slowest operation: {slowest_op[0]} ({np.mean(slowest_op[1]):.6f}s avg)")
    print(
        f"Ratio (slowest/fastest): {np.mean(slowest_op[1]) / np.mean(fastest_op[1]):.1f}x"
    )

    # Calculate potential bottlenecks
    if len(timings) > 1:
        bottleneck = max(timings.items(), key=lambda x: np.sum(x[1]))
        print(
            f"Biggest time consumer: {bottleneck[0]} ({np.sum(bottleneck[1]):.3f}s, {np.sum(bottleneck[1]) / total_time * 100:.1f}% of total)"
        )


def main():
    parser = argparse.ArgumentParser(
        description="Analyze and plot timing data from JSON file"
    )
    parser.add_argument(
        "json_file", help="Path to the JSON file generated by save_timings()"
    )
    parser.add_argument("--save", action="store_true", help="Save plots to files")
    parser.add_argument(
        "--output-dir",
        default="timing_plots",
        help="Directory to save plots (default: timing_plots)",
    )

    args = parser.parse_args()

    plot_timings_from_json(args.json_file, args.save, args.output_dir)


if __name__ == "__main__":
    # If run without command line arguments, you can specify the file here
    # plot_timings_from_json("training_performance.json", save_plots=True)

    main()
